{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d38477-4b5a-4781-86eb-981ce5beb003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import normalize\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Flip(p=0.5),\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1de37e-f6b5-4585-a963-79f56662ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import shutil\n",
    "main_folder = 'RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021'\n",
    "base_dir = 'brains'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "    \n",
    "train_dir  = os.path.join(base_dir,'train')\n",
    "test_dir  = os.path.join(base_dir,'test')\n",
    "valid_dir  = os.path.join(base_dir,'valid')\n",
    "\n",
    "for directory in (train_dir, valid_dir, test_dir):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "        \n",
    "train_brain = os.path.join(train_dir, 'brain')\n",
    "train_mask = os.path.join(train_dir, 'mask')\n",
    "\n",
    "test_brain = os.path.join(test_dir, 'brain')\n",
    "test_mask = os.path.join(test_dir, 'mask')\n",
    "\n",
    "valid_brain = os.path.join(valid_dir, 'brain')\n",
    "valid_mask = os.path.join(valid_dir, 'mask')\n",
    "\n",
    "\n",
    "dirs = [train_brain,train_mask, test_brain, test_mask, valid_brain, valid_mask ]\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53c209c-ae64-4c16-91c2-f2757c13429b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def data_split(path,train_size,val_size,test_size):\n",
    "\n",
    "    \n",
    "    \n",
    "    #normalizacja przy uzyciu clahe\n",
    "    \n",
    "    files  = os.listdir(path)\n",
    "\n",
    "    train_dataset,split_dataset = train_test_split(files,test_size = 1- train_size,random_state = 0)\n",
    "    \n",
    "    test_dataset,valid_dataset = train_test_split(split_dataset,train_size = 0.25,random_state = 0)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit = 0.5)\n",
    "    \n",
    "    for file in train_dataset:\n",
    "        \n",
    "        image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{path}/{file}/{file}_t1.nii.gz').get_fdata()\n",
    "        image_t2 = nib.load(f'{path}/{file}/{file}_t2.nii.gz').get_fdata()\n",
    "\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        img_t2 = image_t2[:,:,60:110]\n",
    "        img_flair = image_flair[:,:,60:110]\n",
    "        img_t1 = image_t1[:,:,60:110]\n",
    "        img_t1ce = image_t1ce[:,:,60:110]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,60:110]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            \n",
    "            \n",
    "                        \n",
    "            imag_t1 = np.array(img_t1[:,:,[image]])\n",
    "            imag_t1ce = np.array(img_t1ce[:,:,[image]])\n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            imag_t2 = np.array(img_t2[:,:,[image]])\n",
    "\n",
    "            \n",
    "            imag_flair = imag_flair[40:200 ,40:200]\n",
    "            imag_t1ce = imag_t1ce[40:200 ,40:200]\n",
    "            imag_t1 = imag_t1[40:200 ,40:200]\n",
    "            imag_t2 = imag_t2[40:200 ,40:200]\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            imag_t1 = (imag_t1/imag_t1.max()) * 255\n",
    "            imag_t1ce = (imag_t1ce/imag_t1ce.max()) * 255\n",
    "            imag_flair = (imag_flair/imag_flair.max()) * 255\n",
    "            imag_t2 = (imag_t2/imag_t2.max()) * 255\n",
    "                       \n",
    "        \n",
    " \n",
    "            imag_t2 = imag_t2.reshape(160,160)\n",
    "                       \n",
    "        \n",
    "   \n",
    "            imag_t1 = imag_t1.reshape(160,160)\n",
    "                       \n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "            imag_t1ce = imag_t1ce.reshape(160,160)\n",
    "                       \n",
    "\n",
    "            imag_flair = imag_flair.reshape(160,160)\n",
    "            \n",
    "            \n",
    "\n",
    "            imag = np.stack([imag_t1,imag_t1ce,imag_flair,imag_t2],axis=2)\n",
    "            \n",
    "            \n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            transformed = transform(image=imag,mask=mask)\n",
    "            \n",
    "            imag = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            mask = mask[40:200 ,40:200]\n",
    "   \n",
    "   \n",
    "                \n",
    "            y_train = mask\n",
    "                \n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            np.save(f'brains/train/mask/{file}{image}',y_train_cat)\n",
    "            np.save(f'brains/train/brain/{file}{image}',imag)\n",
    "            \n",
    "            \n",
    "    \n",
    "    for file in test_dataset:\n",
    "        \n",
    "        image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{path}/{file}/{file}_t1.nii.gz').get_fdata()\n",
    "        image_t2 = nib.load(f'{path}/{file}/{file}_t2.nii.gz').get_fdata()\n",
    "\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        img_t2 = image_t2[:,:,60:110]\n",
    "        img_flair = image_flair[:,:,60:110]\n",
    "        img_t1 = image_t1[:,:,60:110]\n",
    "        img_t1ce = image_t1ce[:,:,60:110]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,60:110]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            \n",
    "            \n",
    "                        \n",
    "            imag_t1 = np.array(img_t1[:,:,[image]])\n",
    "            imag_t1ce = np.array(img_t1ce[:,:,[image]])\n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            imag_t2 = np.array(img_t2[:,:,[image]])\n",
    "\n",
    "            \n",
    "            imag_flair = imag_flair[40:200 ,40:200]\n",
    "            imag_t1ce = imag_t1ce[40:200 ,40:200]\n",
    "            imag_t1 = imag_t1[40:200 ,40:200]\n",
    "            imag_t2 = imag_t2[40:200 ,40:200]\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            imag_t1 = (imag_t1/imag_t1.max()) * 255\n",
    "            imag_t1ce = (imag_t1ce/imag_t1ce.max()) * 255\n",
    "            imag_flair = (imag_flair/imag_flair.max()) * 255\n",
    "            imag_t2 = (imag_t2/imag_t2.max()) * 255\n",
    "                       \n",
    "        \n",
    " \n",
    "            imag_t2 = imag_t2.reshape(160,160)\n",
    "                       \n",
    "        \n",
    "   \n",
    "            imag_t1 = imag_t1.reshape(160,160)\n",
    "                       \n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "            imag_t1ce = imag_t1ce.reshape(160,160)\n",
    "                       \n",
    "\n",
    "            imag_flair = imag_flair.reshape(160,160)\n",
    "            \n",
    "            \n",
    "\n",
    "            imag = np.stack([imag_t1,imag_t1ce,imag_flair,imag_t2],axis=2)\n",
    "            \n",
    "            \n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            transformed = transform(image=imag,mask=mask)\n",
    "            \n",
    "            imag = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            mask = mask[40:200 ,40:200]\n",
    "   \n",
    "   \n",
    "                \n",
    "            y_train = mask\n",
    "                \n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            np.save(f'brains/test/mask/{file}{image}',y_train_cat)\n",
    "            np.save(f'brains/test/brain/{file}{image}',imag)\n",
    "            \n",
    "        \n",
    "    for file in valid_dataset:\n",
    "        \n",
    "        image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{path}/{file}/{file}_t1.nii.gz').get_fdata()\n",
    "        image_t2 = nib.load(f'{path}/{file}/{file}_t2.nii.gz').get_fdata()\n",
    "\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        img_t2 = image_t2[:,:,60:110]\n",
    "        img_flair = image_flair[:,:,60:110]\n",
    "        img_t1 = image_t1[:,:,60:110]\n",
    "        img_t1ce = image_t1ce[:,:,60:110]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,60:110]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            \n",
    "            \n",
    "                        \n",
    "            imag_t1 = np.array(img_t1[:,:,[image]])\n",
    "            imag_t1ce = np.array(img_t1ce[:,:,[image]])\n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            imag_t2 = np.array(img_t2[:,:,[image]])\n",
    "\n",
    "            \n",
    "            imag_flair = imag_flair[40:200 ,40:200]\n",
    "            imag_t1ce = imag_t1ce[40:200 ,40:200]\n",
    "            imag_t1 = imag_t1[40:200 ,40:200]\n",
    "            imag_t2 = imag_t2[40:200 ,40:200]\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            imag_t1 = (imag_t1/imag_t1.max()) * 255\n",
    "            imag_t1ce = (imag_t1ce/imag_t1ce.max()) * 255\n",
    "            imag_flair = (imag_flair/imag_flair.max()) * 255\n",
    "            imag_t2 = (imag_t2/imag_t2.max()) * 255\n",
    "                       \n",
    "        \n",
    " \n",
    "            imag_t2 = imag_t2.reshape(160,160)\n",
    "                       \n",
    "        \n",
    "   \n",
    "            imag_t1 = imag_t1.reshape(160,160)\n",
    "                       \n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "            imag_t1ce = imag_t1ce.reshape(160,160)\n",
    "                       \n",
    "\n",
    "            imag_flair = imag_flair.reshape(160,160)\n",
    "            \n",
    "            \n",
    "\n",
    "            imag = np.stack([imag_t1,imag_t1ce,imag_flair,imag_t2],axis=2)\n",
    "            \n",
    "            \n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            transformed = transform(image=imag,mask=mask)\n",
    "            \n",
    "            imag = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            mask = mask[40:200 ,40:200]\n",
    "   \n",
    "   \n",
    "                \n",
    "            y_train = mask\n",
    "                \n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            np.save(f'brains/valid/mask/{file}{image}',y_train_cat)\n",
    "            np.save(f'brains/valid/brain/{file}{image}',imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce78efa-7685-492d-a520-03bdb4d9af41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "def data_split(path,train_size,val_size,test_size,contrast):\n",
    "    \n",
    "    #wykorzystac informacje z maski (niekoniecznie 70-111)\n",
    "    #maksymalny obszar ktory zawiera mozg bez backgroundu dla kazdego pacjenta i potem przeskalowac resize'owac do nizszego - tez nie za mały\n",
    "    #raportowac wyniki dla kazdej klasy osobno\n",
    "    \n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    \n",
    "    files  = os.listdir(path)\n",
    "\n",
    "    train_dataset,split_dataset = train_test_split(files,test_size = 1- train_size,random_state = 0)\n",
    "    \n",
    "    test_dataset,valid_dataset = train_test_split(split_dataset,train_size = 0.75,random_state = 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for file in train_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_{contrast}.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,65:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,65:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "\n",
    "            mask = mask[40:200 ,40:200]\n",
    "   \n",
    "   \n",
    "                \n",
    "            y_train = mask\n",
    "                \n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            imag_flair = imag_flair[40:200 ,40:200]\n",
    "\n",
    "            imag_flair = (imag_flair/imag_flair.max()) * 255\n",
    "                       \n",
    "        \n",
    "            \n",
    "        \n",
    "            img = imag_flair\n",
    "            \n",
    "            img = img.astype('uint8')\n",
    "            \n",
    "            clahe = cv2.createCLAHE(clipLimit = 0.5)\n",
    "\n",
    "            imag_flair = clahe.apply(img) \n",
    "            \n",
    "            imag_flair = imag_flair.astype('float32')\n",
    "\n",
    "        \n",
    "            np.save(f'brains/train/mask/{file}{image}',y_train_cat)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(f'brains/train/brain/{file}{image}',imag_flair)   \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    for file in test_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_{contrast}.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,65:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,65:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "\n",
    "            mask = mask[40:200 ,40:200]\n",
    "\n",
    "   \n",
    "   \n",
    "                \n",
    "            y_train = mask\n",
    "                \n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            imag_flair = imag_flair[40:200 ,40:200]\n",
    "            imag_flair = (imag_flair/imag_flair.max()) * 255\n",
    "                       \n",
    "        \n",
    "            \n",
    "        \n",
    "            img = imag_flair\n",
    "            \n",
    "            img = img.astype('uint8')\n",
    "            \n",
    "            clahe = cv2.createCLAHE(clipLimit = 0.5)\n",
    "\n",
    "            imag_flair = clahe.apply(img) \n",
    "            \n",
    "            imag_flair = imag_flair.astype('float32')\n",
    "\n",
    "        \n",
    "        \n",
    "            np.save(f'brains/test/mask/{file}{image}',y_train_cat)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(f'brains/test/brain/{file}{image}',imag_flair)   \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    for file in valid_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_{contrast}.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,65:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,65:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "\n",
    "\n",
    "   \n",
    "            mask = mask[40:200 ,40:200]\n",
    "\n",
    "                \n",
    "            y_train = mask\n",
    "                \n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            imag_flair = imag_flair[40:200 ,40:200]\n",
    "\n",
    "            imag_flair = (imag_flair/imag_flair.max()) * 255\n",
    "                       \n",
    "        \n",
    "            \n",
    "        \n",
    "            img = imag_flair\n",
    "            \n",
    "            img = img.astype('uint8')\n",
    "            \n",
    "            clahe = cv2.createCLAHE(clipLimit = 0.5)\n",
    "\n",
    "            imag_flair = clahe.apply(img) \n",
    "            \n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            np.save(f'brains/valid/mask/{file}{image}',y_train_cat)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(f'brains/valid/brain/{file}{image}',imag_flair)   \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dad0bc8-876a-4d54-8af5-4d1378daebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machine2\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CLAHE transformation expects 1-channel or 3-channel images.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2896\\3108893589.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2896\\4022393709.py\u001b[0m in \u001b[0;36mdata_split\u001b[1;34m(path, train_size, val_size, test_size)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mtransformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mimag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\machine2\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_each_transform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\machine2\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                     )\n\u001b[0;32m    117\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\machine2\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[1;34m(self, params, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mtarget_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_target_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mtarget_dependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_dependence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtarget_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\machine2\\lib\\site-packages\\albumentations\\augmentations\\transforms.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, img, clip_limit, **params)\u001b[0m\n\u001b[0;32m   1306\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rgb_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_grayscale_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CLAHE transformation expects 1-channel or 3-channel images.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclahe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile_grid_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: CLAHE transformation expects 1-channel or 3-channel images."
     ]
    }
   ],
   "source": [
    "data_split(main_folder,0.70,0.20,0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "772437b1-01b5-4a05-9eb8-35400e9bfdd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_load_generator(path,batch_size):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    files = os.listdir(f'{path}/mask')\n",
    "    \n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_size_end = batch_size\n",
    "        while batch_start < len(files):\n",
    "            limit = min(batch_size_end,len(files))\n",
    "            \n",
    "            files_batched = files[batch_start:limit]\n",
    "            \n",
    "            #loading data\n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            for file in files_batched:\n",
    "                X_train = plt.imread(f'{path}/brain/{file}')\n",
    "                Y_train = plt.imread(f'{path}/mask/{file}')\n",
    "            \n",
    "  \n",
    "                X.append(np.array(X_train))\n",
    "                Y.append(np.array(Y_train))\n",
    "            \n",
    "            \n",
    "            x_train = np.array(X)\n",
    "            \n",
    "            \n",
    "            y_train = np.array(Y)\n",
    "            \n",
    "            \n",
    "            y_train = y_train.reshape(batch_size,240,240)\n",
    "            \n",
    "            x_train = x_train.reshape(batch_size,240,240)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "            from keras.utils import normalize\n",
    "            x_train = np.expand_dims(x_train,axis=3)\n",
    "            x_train = normalize(x_train,axis=1)\n",
    "\n",
    "            \n",
    "            from keras.utils import to_categorical\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "\n",
    "            \n",
    "            yield(x_train,y_train_cat)\n",
    "            \n",
    "            batch_start +=batch_size\n",
    "            batch_size_end +=batch_size\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be281621-8732-4748-893a-cce02b65d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gener = image_load_generator('brains/train',9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43feef62-9aab-41cf-9194-76139bc8a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = next(gener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aacb1e3-b195-4a2b-b926-d145cea6c2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 240, 240, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57311f00-e7ce-4d46-b3b0-494bdbd3fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f96358b-a364-4568-b1d8-7d514691ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "path = 'RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021'\n",
    "file = 'BraTS2021_00002'\n",
    "image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "image_t1 = nib.load(f'{path}/{file}/{file}_t1.nii.gz').get_fdata()\n",
    "\n",
    "img_t1 = image_t1ce[:,:,90]\n",
    "img_flair = image_flair[:,:,90]\n",
    "img_t1 = image_t1[:,:,90]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed366edc-8da2-4c19-94ee-d7ec78387671",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.stack([img_t1,img_flair,img_t1],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d4856f1-51f8-4ba1-8ea2-82c7d834c4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134f452f-b68a-4abc-849f-e7d92755df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [5,6,7,8,9]\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    \n",
    "    x = lista[i]\n",
    "    \n",
    "    y = x*2\n",
    "    \n",
    "    lista[i] = y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e1e949-ac0f-4e21-b22c-cdee631a3613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 12, 14, 16, 18]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31298819-afcc-43c6-8c7e-aeb578cc964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "files = os.listdir('RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021')\n",
    "train,test = train_test_split(files,test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea77c50e-d928-4955-9572-70e584b651f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6491d-a5b0-4361-8433-1d62c3ee5837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2eb6ff-d39b-4e6d-86fb-83e4002037ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbc4f2-d800-441a-a42f-505b1cc69956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677dc3d4-dad0-4a6c-ba69-b9beb32289f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def data_split(path,train_size,val_size,test_size):\n",
    "    \n",
    "    #wykorzystac informacje z maski (niekoniecznie 70-111)\n",
    "    #maksymalny obszar ktory zawiera mozg bez backgroundu dla kazdego pacjenta i potem przeskalowac resize'owac do nizszego - tez nie za mały\n",
    "    #raportowac wyniki dla kazdej klasy osobno\n",
    "    \n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    \n",
    "    files  = os.listdir(path)\n",
    "\n",
    "    train = round(train_size * len(files))\n",
    "    test = round(test_size * len(files))\n",
    "    valid = round(val_size * len(files))\n",
    "    \n",
    "    train_dataset = files[0:train]\n",
    "    test_dataset = files[train:train+test]\n",
    "    valid_dataset = files[train+test:len(files)]\n",
    "    \n",
    "    \n",
    "    for file in train_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "\n",
    "        img_flair = image_flair[:,:,80:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,80:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            \n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            flipped_mask = tf.image.flip_left_right(mask)\n",
    "            rotated_mask = tf.image.rot90(mask)\n",
    "            rotated2_mask = tf.image.rot90(rotated_mask)\n",
    "            \n",
    "            flipped_mask = np.array(flipped_mask)\n",
    "            rotated_mask = np.array(rotated_mask)\n",
    "            rotated2_mask = np.array(rotated2_mask)\n",
    "            \n",
    "            masks_st = [mask,flipped_mask,rotated_mask,rotated2_mask]\n",
    "            \n",
    "            for i in range(len(masks_st)):\n",
    "                \n",
    "                y_train = masks_st[i]\n",
    "                \n",
    "                labelencoder = LabelEncoder()\n",
    "                n,h,w = y_train.shape\n",
    "                y_train_reshape = y_train.reshape(-1,1)\n",
    "                y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "                y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "                y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "                train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "                y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "                \n",
    "                \n",
    "                masks_st[i] = y_train_cat\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            flipped = tf.image.flip_left_right(imag_flair)\n",
    "            rotated = tf.image.rot90(imag_flair)    \n",
    "            rotated2 = tf.image.rot90(rotated)\n",
    "            \n",
    "                \n",
    "            flipped = np.array(flipped)\n",
    "            rotated = np.array(rotated)\n",
    "            rotated2 = np.array(rotated2)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "            np.save(f'brains/train/mask/{file}{image}',masks_st[0])\n",
    "            np.save(f'brains/train/mask/{file}{image}1',masks_st[1])\n",
    "            np.save(f'brains/train/mask/{file}{image}2',masks_st[2])\n",
    "            np.save(f'brains/train/mask/{file}{image}3',masks_st[3])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(f'brains/train/brain/{file}{image}',imag_flair)   \n",
    "            np.save(f'brains/train/brain/{file}{image}1',flipped)\n",
    "            np.save(f'brains/train/brain/{file}{image}2',rotated)\n",
    "            np.save(f'brains/train/brain/{file}{image}3',rotated2)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    for file in test_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        img_flair = image_flair[:,:,80:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,80:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            flipped_mask = tf.image.flip_left_right(mask)\n",
    "            rotated_mask = tf.image.rot90(mask)\n",
    "            rotated2_mask = tf.image.rot90(rotated_mask)\n",
    "            \n",
    "            flipped_mask = np.array(flipped_mask)\n",
    "            rotated_mask = np.array(rotated_mask)\n",
    "            rotated2_mask = np.array(rotated2_mask)\n",
    "            \n",
    "            masks_st = [mask,flipped_mask,rotated_mask,rotated2_mask]\n",
    "            \n",
    "            for i in range(len(masks_st)):\n",
    "                \n",
    "                y_train = masks_st[i]\n",
    "                \n",
    "                labelencoder = LabelEncoder()\n",
    "                n,h,w = y_train.shape\n",
    "                y_train_reshape = y_train.reshape(-1,1)\n",
    "                y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "                y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "                y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "                train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "                y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "                \n",
    "                \n",
    "                masks_st[i] = y_train_cat\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            flipped = tf.image.flip_left_right(imag_flair)\n",
    "            rotated = tf.image.rot90(imag_flair)    \n",
    "            rotated2 = tf.image.rot90(rotated)\n",
    "            \n",
    "                \n",
    "            flipped = np.array(flipped)\n",
    "            rotated = np.array(rotated)\n",
    "            rotated2 = np.array(rotated2)\n",
    "                  \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            np.save(f'brains/test/mask/{file}{image}',masks_st[0])\n",
    "            np.save(f'brains/test/mask/{file}{image}1',masks_st[1])\n",
    "            np.save(f'brains/test/mask/{file}{image}2',masks_st[2])\n",
    "            np.save(f'brains/test/mask/{file}{image}3',masks_st[3])\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(f'brains/test/brain/{file}{image}',imag_flair)   \n",
    "            np.save(f'brains/test/brain/{file}{image}1',flipped)\n",
    "            np.save(f'brains/test/brain/{file}{image}2',rotated)\n",
    "            np.save(f'brains/test/brain/{file}{image}3',rotated2)\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    for file in valid_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,80:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,80:105]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            flipped_mask = tf.image.flip_left_right(mask)\n",
    "            rotated_mask = tf.image.rot90(mask)\n",
    "            rotated2_mask = tf.image.rot90(rotated_mask)\n",
    "            \n",
    "            flipped_mask = np.array(flipped_mask)\n",
    "            rotated_mask = np.array(rotated_mask)\n",
    "            rotated2_mask = np.array(rotated2_mask)\n",
    "            \n",
    "            masks_st = [mask,flipped_mask,rotated_mask,rotated2_mask]\n",
    "            \n",
    "            for i in range(len(masks_st)):\n",
    "                \n",
    "                y_train = masks_st[i]\n",
    "                \n",
    "                labelencoder = LabelEncoder()\n",
    "                n,h,w = y_train.shape\n",
    "                y_train_reshape = y_train.reshape(-1,1)\n",
    "                y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "                y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "                y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "\n",
    "\n",
    "                train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "                \n",
    "                y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "                \n",
    "                \n",
    "                masks_st[i] = y_train_cat\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            flipped = tf.image.flip_left_right(imag_flair)\n",
    "            rotated = tf.image.rot90(imag_flair)    \n",
    "            rotated2 = tf.image.rot90(rotated)\n",
    "            \n",
    "                \n",
    "      \n",
    "            flipped = np.array(flipped)\n",
    "            rotated = np.array(rotated)\n",
    "            rotated2 = np.array(rotated2)\n",
    "                       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            np.save(f'brains/valid/mask/{file}{image}',masks_st[0])\n",
    "            np.save(f'brains/valid/mask/{file}{image}1',masks_st[1])\n",
    "            np.save(f'brains/valid/mask/{file}{image}2',masks_st[2])\n",
    "            np.save(f'brains/valid/mask/{file}{image}3',masks_st[3])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            np.save(f'brains/valid/brain/{file}{image}',imag_flair)   \n",
    "            np.save(f'brains/valid/brain/{file}{image}1',flipped)\n",
    "            np.save(f'brains/valid/brain/{file}{image}2',rotated)\n",
    "            np.save(f'brains/valid/brain/{file}{image}3',rotated2)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42ead9c-3c7c-4ccb-b7c6-7519b134c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = os.listdir('brains/train/brain')\n",
    "train = os.listdir('brains/valid/brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e34413-cf26-4b27-8fd7-f27cfc9a1190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1fdc07-d049-4ca8-adaf-ed438aa0f923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
