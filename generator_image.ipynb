{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d38477-4b5a-4781-86eb-981ce5beb003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import normalize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edb46a4-7f21-4b3f-8b9e-4e3370e3fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_generator(path,\n",
    "                    img_train_dir,\n",
    "                    img_mask_dir,\n",
    "                    batch_size):\n",
    "    \n",
    "    image_train_list = os.listdir(img_train_dir)\n",
    "    image_mask_list =  os.listdir(img_mask_dir)\n",
    "    \n",
    "    \n",
    "\n",
    "    yield(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1de37e-f6b5-4585-a963-79f56662ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import shutil\n",
    "\n",
    "#sklearn.utils.shuffle() \n",
    "# array1 = np.array([[1, 1], [2, 2], [3, 3]])\n",
    "# array2 = np.array([1, 2, 3])\n",
    "\n",
    "# array1_shuffled, array2_shuffled = sklearn.utils.shuffle(array1, array2)\n",
    "\n",
    "# print(array1_shuffled)\n",
    "# OUTPUT\n",
    "# [[3 3]\n",
    "#  [1 1]\n",
    "#  [2 2]]\n",
    "# print(array2_shuffled)\n",
    "# OUTPUT\n",
    "# [3 1 2]\n",
    "\n",
    "\n",
    "\n",
    "main_folder = 'RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021'\n",
    "base_dir = 'brains'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "    \n",
    "train_dir  = os.path.join(base_dir,'train')\n",
    "test_dir  = os.path.join(base_dir,'test')\n",
    "valid_dir  = os.path.join(base_dir,'valid')\n",
    "\n",
    "for directory in (train_dir, valid_dir, test_dir):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "        \n",
    "train_brain = os.path.join(train_dir, 'brain')\n",
    "train_mask = os.path.join(train_dir, 'mask')\n",
    "\n",
    "test_brain = os.path.join(test_dir, 'brain')\n",
    "test_mask = os.path.join(test_dir, 'mask')\n",
    "\n",
    "valid_brain = os.path.join(valid_dir, 'brain')\n",
    "valid_mask = os.path.join(valid_dir, 'mask')\n",
    "\n",
    "\n",
    "dirs = [train_brain,train_mask, test_brain, test_mask, valid_brain, valid_mask ]\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a53c209c-ae64-4c16-91c2-f2757c13429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(path,train_size,val_size,test_size):\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    \n",
    "    files  = os.listdir(path)\n",
    "\n",
    "    train = round(train_size * len(files))\n",
    "    test = round(test_size * len(files))\n",
    "    valid = round(val_size * len(files))\n",
    "    \n",
    "    train_dataset = files[0:train]\n",
    "    test_dataset = files[train:train+test]\n",
    "    valid_dataset = files[train+test:train+test+valid]\n",
    "    \n",
    "    \n",
    "    for file in train_dataset:\n",
    "        \n",
    "        image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{path}/{file}/{file}_t2.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,90:111]\n",
    "        img_t1 = image_t1[:,:,90:111]\n",
    "        img_t1ce = image_t1ce[:,:,90:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,90:111]\n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            imag_t1 = np.array(img_t1[:,:,[image]])\n",
    "            imag_t1ce = np.array(img_t1ce[:,:,[image]])\n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            imag = np.stack([imag_t1,imag_t1ce,imag_flair],axis=2)\n",
    "            \n",
    "            np.save(f'brains/train/mask/{file}{image}',mask)\n",
    "            np.save(f'brains/train/brain/{file}{image}',imag)\n",
    "            \n",
    "            \n",
    "    \n",
    "    for file in test_dataset:\n",
    "        \n",
    "        image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{path}/{file}/{file}_t2.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "\n",
    "        \n",
    "        img_flair = image_flair[:,:,90:111]\n",
    "        img_t1 = image_t1[:,:,90:111]\n",
    "        img_t1ce = image_t1ce[:,:,90:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,90:111]\n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            imag_t1 = np.array(img_t1[:,:,[image]])\n",
    "            imag_t1ce = np.array(img_t1ce[:,:,[image]])\n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            imag = np.stack([imag_t1,imag_t1ce,imag_flair],axis=2)\n",
    "            \n",
    "            np.save(f'brains/test/mask/{file}{image}',mask)\n",
    "            np.save(f'brains/test/brain/{file}{image}',imag)\n",
    "            \n",
    "        \n",
    "    for file in valid_dataset:\n",
    "        \n",
    "        image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{path}/{file}/{file}_t2.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "\n",
    "        \n",
    "        img_flair = image_flair[:,:,90:111]\n",
    "        img_t1 = image_t1[:,:,90:111]\n",
    "        img_t1ce = image_t1ce[:,:,90:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,90:111]\n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            imag_t1 = np.array(img_t1[:,:,[image]])\n",
    "            imag_t1ce = np.array(img_t1ce[:,:,[image]])\n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            imag = np.stack([imag_t1,imag_t1ce,imag_flair],axis=2)\n",
    "            \n",
    "            np.save(f'brains/valid/mask/{file}{image}',mask)\n",
    "            np.save(f'brains/valid/brain/{file}{image}',imag)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664b5829-41cd-493e-9199-c06c8a013975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(path,train_size,val_size,test_size):\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    \n",
    "    files  = os.listdir(path)\n",
    "\n",
    "    train = round(train_size * len(files))\n",
    "    test = round(test_size * len(files))\n",
    "    valid = round(val_size * len(files))\n",
    "    \n",
    "    train_dataset = files[0:train]\n",
    "    test_dataset = files[train:train+test]\n",
    "    valid_dataset = files[train+test:train+test+valid]\n",
    "    \n",
    "    \n",
    "    for file in train_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "\n",
    "        img_flair = image_flair[:,:,70:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,70:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            \n",
    "            np.save(f'brains/train/mask/{file}{image}',mask)\n",
    "            np.save(f'brains/train/brain/{file}{image}',imag_flair)\n",
    "            \n",
    "            \n",
    "    \n",
    "    for file in test_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,70:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,70:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            \n",
    "            np.save(f'brains/test/mask/{file}{image}',mask)\n",
    "            np.save(f'brains/test/brain/{file}{image}',imag_flair)\n",
    "            \n",
    "            \n",
    "        \n",
    "    for file in valid_dataset:\n",
    "        \n",
    "        image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{path}/{file}/{file}_seg.nii.gz').get_fdata()\n",
    "        \n",
    "        img_flair = image_flair[:,:,70:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        masks = image_seg[:,:,70:111]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image in range(0,masks.shape[2]):\n",
    "            mask = np.array(masks[:,:,[image]])\n",
    "            \n",
    "            imag_flair = np.array(img_flair[:,:,[image]])\n",
    "            \n",
    "            \n",
    "            np.save(f'brains/valid/mask/{file}{image}',mask)\n",
    "            np.save(f'brains/valid/brain/{file}{image}',imag_flair)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dad0bc8-876a-4d54-8af5-4d1378daebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split(main_folder,0.60,0.20,0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "772437b1-01b5-4a05-9eb8-35400e9bfdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_load_generator(path,batch_size):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    files = os.listdir(f'{path}/mask')\n",
    "    \n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_size_end = batch_size\n",
    "        while batch_start < len(files):\n",
    "            limit = min(batch_size_end,len(files))\n",
    "            \n",
    "            files_batched = files[batch_start:limit]\n",
    "            \n",
    "            #loading data\n",
    "            X = []\n",
    "            Y = []\n",
    "            \n",
    "            for file in files_batched:\n",
    "                X_train = plt.imread(f'{path}/brain/{file}')\n",
    "                Y_train = plt.imread(f'{path}/mask/{file}')\n",
    "            \n",
    "  \n",
    "                X.append(np.array(X_train))\n",
    "                Y.append(np.array(Y_train))\n",
    "            \n",
    "            \n",
    "            x_train = np.array(X)\n",
    "            \n",
    "            \n",
    "            y_train = np.array(Y)\n",
    "            \n",
    "            \n",
    "            y_train = y_train.reshape(batch_size,240,240)\n",
    "            \n",
    "            x_train = x_train.reshape(batch_size,240,240)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            labelencoder = LabelEncoder()\n",
    "            n,h,w = y_train.shape\n",
    "            y_train_reshape = y_train.reshape(-1,1)\n",
    "            y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "            y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "\n",
    "\n",
    "            y_train = np.expand_dims(y_train_encoded, axis=3)\n",
    "\n",
    "            from keras.utils import normalize\n",
    "            x_train = np.expand_dims(x_train,axis=3)\n",
    "            x_train = normalize(x_train,axis=1)\n",
    "\n",
    "            \n",
    "            from keras.utils import to_categorical\n",
    "            train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "            y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "\n",
    "            \n",
    "            yield(x_train,y_train_cat)\n",
    "            \n",
    "            batch_start +=batch_size\n",
    "            batch_size_end +=batch_size\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be281621-8732-4748-893a-cce02b65d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gener = image_load_generator('brains/train',9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43feef62-9aab-41cf-9194-76139bc8a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = next(gener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aacb1e3-b195-4a2b-b926-d145cea6c2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 240, 240, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57311f00-e7ce-4d46-b3b0-494bdbd3fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f96358b-a364-4568-b1d8-7d514691ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "path = 'RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021'\n",
    "file = 'BraTS2021_00002'\n",
    "image_t1ce = nib.load(f'{path}/{file}/{file}_t1ce.nii.gz').get_fdata()\n",
    "image_flair = nib.load(f'{path}/{file}/{file}_flair.nii.gz').get_fdata()\n",
    "image_t1 = nib.load(f'{path}/{file}/{file}_t1.nii.gz').get_fdata()\n",
    "\n",
    "img_t1 = image_t1ce[:,:,90]\n",
    "img_flair = image_flair[:,:,90]\n",
    "img_t1 = image_t1[:,:,90]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed366edc-8da2-4c19-94ee-d7ec78387671",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.stack([img_t1,img_flair,img_t1],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d4856f1-51f8-4ba1-8ea2-82c7d834c4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 240, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f452f-b68a-4abc-849f-e7d92755df7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
