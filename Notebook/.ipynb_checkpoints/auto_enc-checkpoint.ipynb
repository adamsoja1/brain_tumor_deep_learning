{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec63ce8f-c44e-4f9b-bbfa-9e17556a506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a1f943-0ed0-4264-a5e3-8d3292bf10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self,path):\n",
    "        self.path = path\n",
    "        \n",
    "    def get_list_files(self):\n",
    "        \n",
    "        return sorted(os.listdir(self.path))\n",
    "    \n",
    "    def get_random_images(self,channel,which_chan):\n",
    "        random_brain_dir = random.choice(self.get_list_files())\n",
    "        exact_path = self.path + '/' + random_brain_dir\n",
    "\n",
    "        number_of_image = random_brain_dir[-5:]\n",
    "        \n",
    "        image_flair = nib.load(f'{exact_path}/BraTS2021_{number_of_image}_flair.nii.gz').get_fdata()\n",
    "        image_seg = nib.load(f'{exact_path}/BraTS2021_{number_of_image}_seg.nii.gz').get_fdata()\n",
    "        image_t1 = nib.load(f'{exact_path}/BraTS2021_{number_of_image}_t1.nii.gz').get_fdata()\n",
    "        image_t1ce = nib.load(f'{exact_path}/BraTS2021_{number_of_image}_t1ce.nii.gz').get_fdata()\n",
    "        image_t2 = nib.load(f'{exact_path}/BraTS2021_{number_of_image}_t2.nii.gz').get_fdata()\n",
    "        \n",
    "        which_channel =which_chan\n",
    "        if which_channel == 1:\n",
    "            mid_slice_flair = image_flair[channel,:,:]\n",
    "            mid_slice_t1 = image_t1[channel,:,:]\n",
    "            mid_slice_t1ce = image_t1ce[channel,:,:]\n",
    "            mid_slice_t2 = image_t2[channel,:,:]\n",
    "        \n",
    "        elif which_channel == 2:\n",
    "            \n",
    "            mid_slice_flair = image_flair[:,channel,:]\n",
    "            mid_slice_t1 = image_t1[:,channel,:]\n",
    "            mid_slice_t1ce = image_t1ce[:,channel,:]\n",
    "            mid_slice_t2 = image_t2[:,channel,:]\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif which_channel == 3:\n",
    "            mid_slice_flair = image_flair[:,:,channel]\n",
    "            mid_slice_t1 = image_t1[:,:,channel]\n",
    "            mid_slice_t1ce = image_t1ce[:,:,channel]\n",
    "            mid_slice_t2 = image_t2[:,:,channel]\n",
    "            \n",
    "            \n",
    "        \n",
    "        fig,axes = plt.subplots(2, 3, figsize=(30, 25))    \n",
    "\n",
    "        fig.suptitle(f'Mozg nr {number_of_image}', fontsize=40)\n",
    "        mid_slice_seg = image_seg[:,:,channel]\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        axes[0,0].imshow(mid_slice_flair.T,cmap='gray', origin='lower')\n",
    "        axes[0,0].set_title('Flair')\n",
    "            \n",
    "        axes[0,1].imshow(mid_slice_t1.T,cmap='gray', origin='lower')\n",
    "        axes[0,1].set_title('t1')\n",
    "            \n",
    "        axes[0,2].imshow(mid_slice_t1ce.T,cmap='gray', origin='lower')\n",
    "        axes[0,2].set_title('t1ce')\n",
    "            \n",
    "        axes[1,0].imshow(mid_slice_t2.T,cmap='gray', origin='lower')\n",
    "        axes[1,0].set_title('t2')\n",
    "            \n",
    "        axes[1,1].imshow(mid_slice_seg.T,cmap='gray', origin='lower')\n",
    "        axes[1,1].set_title('t1seg')\n",
    "            \n",
    "        axes[1,2].imshow(mid_slice_seg.T, origin='lower')\n",
    "        axes[1,2].set_title('t1seg')\n",
    "            \n",
    "        \n",
    "    def get_data_train(self):\n",
    "        path_dirs = self.path\n",
    "        files = self.get_list_files()[:1200]\n",
    "        \n",
    "        brain = []\n",
    "        seg = []\n",
    "  \n",
    "        for file in files:\n",
    "            image_seg = nib.load(f'{self.path}/{file}/BraTS2021_{file[-5:]}_seg.nii.gz').get_fdata()            \n",
    "            \n",
    "            mid_slice_seg = image_seg[:,:,75]\n",
    "            \n",
    "            seg.append(np.array(mid_slice_seg))\n",
    "           \n",
    "            \n",
    "            \n",
    "        for file in files:\n",
    "            image_t1ce = nib.load(f'{self.path}/{file}/BraTS2021_{file[-5:]}_t1ce.nii.gz').get_fdata()\n",
    "            mid_slice_t1ce = image_t1ce[:,:,75]\n",
    "            brain.append(np.array(mid_slice_t1ce))\n",
    "            \n",
    "        return np.array(seg),np.array(brain)\n",
    "            \n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea96320-ae75-4b69-95d0-32bbedc2b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = DataLoader('RSNA_ASNR_MICCAI_BraTS2021_TrainingData_16July2021')\n",
    "y_train,x_train = load.get_data_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55146057-8c3a-4bf7-925d-1dd0f1b385e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37131a6c-1e36-46f1-b206-0f56e32a8226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machine\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n,h,w = y_train.shape\n",
    "y_train_reshape = y_train.reshape(-1,1)\n",
    "y_train_reshape_encode = labelencoder.fit_transform(y_train_reshape)\n",
    "y_train_encoded = y_train_reshape_encode.reshape(n,h,w)\n",
    "np.unique(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f232b87-acc6-40f6-8dfd-73a6bfb0076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize\n",
    "x_train = np.expand_dims(x_train,axis=3)\n",
    "x_train = normalize(x_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6085c56-72cb-4107-a726-8c0bc2ef39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1,X_test,y1,y_test = train_test_split(x_train,y_train,train_size = 0.8,test_size=0.2)\n",
    "X_train,X_do_not,y_train,y_do_not = train_test_split(X1,y1,train_size = 0.8,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92bbefe3-b0c1-4329-80f5-a571ff26b07d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9460\\3305670383.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_masks_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_masks_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_masks_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\machine\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train,num_classes = 4)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0],y_train.shape[1],y_train.shape[2],4))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test,num_classes = 4)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0],y_test.shape[1],y_test.shape[2],4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61993be-ac44-4c02-8e16-a9c1aad71304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train_reshape_encode),y_train_reshape_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1385b61e-603c-45be-af83-84f87cd26876",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import initializers\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, Reshape, Flatten, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.losses import categorical_crossentropy\n",
    "def unet(input_size = (240,240,1)):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu' ,padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu' ,padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(3, 1,activation ='softmax',)(conv9)\n",
    "\n",
    "    model = Model(inputs,  conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = [dice_coef])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = unet(input_size = (240,240,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010a559-6c3c-4413-9b31-e7f7c31ce50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(x_train,y_train,epochs=1,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96feb15-2ca9-4892-b526-150267b9a47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a59a9-c509-4e4c-8d33-a56697782918",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = plt.imread('brains/train/brain3/00011.png')\n",
    "\n",
    "pred = pred.reshape(1,240,240,1)/255\n",
    "x_pred = model.predict(pred)\n",
    "x_pred = np.argmax(x_pred)\n",
    "x_pred = x_pred.reshape(240,240)\n",
    "x_pred = x_pred * 255\n",
    "plt.imshow(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea804f-160d-40ee-99ad-8063494095c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = plt.imread('brains/train/brain3/00011.png')\n",
    "plt.imshow(pred1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fd928-31d9-4bea-a896-94492eba152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 =  plt.imread('brains/seg3/00011.png')\n",
    "plt.imshow(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f6515-1cbf-4482-bc5b-6559aff6db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = x_pred.reshape(240,240)\n",
    "\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb92ac6-550a-4f77-8b3c-108c120fa0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a15a2-373c-4862-b573-39629456724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = plt.imread('brains/train/brain3/00012.png')\n",
    "plt.imshow(img,cmap='gray')\n",
    "\n",
    "img = img/255\n",
    "img = img.reshape(1,240,240,1)\n",
    "y_pred = model.predict(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c62d1-a96a-46a6-85aa-ad094829ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = plt.imread('brains/seg3/00012.png')\n",
    "plt.imshow(img,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b093a1-fea6-4192-96e0-cfb3507fb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(240,240)*255\n",
    "plt.imshow(y_pred,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697434f7-d7a7-4aa5-8c82-f593882e2ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dfc92-a5a4-4b11-b025-978cee2ed2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c6347-9479-44ed-bea5-2a7d8d088fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = plt.imread('brains/train/brain3/00639.png')\n",
    "y_p = y_p/255\n",
    "y_p = y_p.astype('float32')\n",
    "y_p = y_p.reshape(1,240,240,1)\n",
    "pred_y = model.predict(y_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62a5d0-c839-4042-84b0-450a96c275df",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pred_y.reshape(240,240)*255\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8c1b6-9072-4341-bd4a-2b49ca64ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_px = plt.imread('brains/train/brain3/00639.png')\n",
    "plt.imshow(y_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84ea7b-aa70-479b-9a67-fbcf4e27b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = plt.imread('brains/seg3/00639.png')\n",
    "plt.imshow(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3445f-b3cf-4eda-85d1-9a5bbde66635",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = y_p + y_px\n",
    "plt.imshow(ses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2128cf-121b-4c86-845e-509325a67423",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = x_train[0] - y_train[0]\n",
    "temp1 = x_train[0] + y_train[0]\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73430b77-5aec-45d7-adb3-e19038f48186",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b1e52-07aa-4a88-827d-3f81337112d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f071849c-aa8e-418a-8eca-bc92f219d961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920b370-e335-4593-a307-78cc74fae836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8b5cf-efe0-4c6e-85bf-246d427c3ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
